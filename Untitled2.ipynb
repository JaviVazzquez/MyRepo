{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP0sWoUVFqP9cfYSyEldDlb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaviVazzquez/MyRepo/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE_l1EfOroZ4"
      },
      "source": [
        "# agents.py - Agent and Controllers\n",
        "# AIFCA Python3 code Version 0.7.1 Documentation at http://aipython.org\n",
        "\n",
        "# Artificial Intelligence: Foundations of Computational Agents\n",
        "# http://artint.info\n",
        "# Copyright David L Poole and Alan K Mackworth 2017.\n",
        "# This work is licensed under a Creative Commons\n",
        "# Attribution-NonCommercial-ShareAlike 4.0 International License.\n",
        "# See: http://creativecommons.org/licenses/by-nc-sa/4.0/deed.en\n",
        "\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from utilities import Displayable\n",
        "\n",
        "\n",
        "class Agent(object):\n",
        "    def __init__(self, env):\n",
        "        \"\"\"set up the agent\"\"\"\n",
        "        self.env = env\n",
        "\n",
        "    def go(self, n):\n",
        "        \"\"\"acts for n time steps\"\"\"\n",
        "        raise NotImplementedError(\"go\")   # abstract method\n",
        "\n",
        "\n",
        "class Environment(Displayable):\n",
        "    def initial_percepts(self):\n",
        "        \"\"\"returns the initial percepts for the agent\"\"\"\n",
        "        raise NotImplementedError(\"initial_percepts\")   # abstract method\n",
        "\n",
        "    def do(self, action):\n",
        "        \"\"\"does the action in the environment\n",
        "        returns the next percept \"\"\"\n",
        "        raise NotImplementedError(\"do\")   # abstract method\n",
        "\n",
        "\n",
        "class TP_env(Environment):\n",
        "    prices = [234, 234, 234, 234, 255, 255, 275, 275, 211, 211, 211,\n",
        "              234, 234, 234, 234, 199, 199, 275, 275, 234, 234, 234, 234, 255,\n",
        "              255, 260, 260, 265, 265, 265, 265, 270, 270, 255, 255, 260, 260,\n",
        "              265, 265, 150, 150, 265, 265, 270, 270, 255, 255, 260, 260, 265,\n",
        "              265, 265, 265, 270, 270, 211, 211, 255, 255, 260, 260, 265, 265,\n",
        "              260, 265, 270, 270, 205, 255, 255, 260, 260, 265, 265, 265, 265,\n",
        "              270, 270]\n",
        "    max_price_addon = 20  # maximum of random value added to get price\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"paper buying agent\"\"\"\n",
        "        self.time = 0\n",
        "        self.stock = 20\n",
        "        self.stock_history = []  # memory of the stock history\n",
        "        self.price_history = []  # memory of the price history\n",
        "\n",
        "    def initial_percepts(self):\n",
        "        \"\"\"return initial percepts\"\"\"\n",
        "        self.stock_history.append(self.stock)\n",
        "        price = self.prices[0] + random.randrange(self.max_price_addon)\n",
        "        self.price_history.append(price)\n",
        "        return {'price': price,\n",
        "                'instock': self.stock}\n",
        "\n",
        "    def do(self, action):\n",
        "        \"\"\"does action (buy) and returns percepts (price and instock)\"\"\"\n",
        "        used = pick_from_dist({6: 0.1, 5: 0.1, 4: 0.2, 3: 0.3, 2: 0.2, 1: 0.1})\n",
        "        bought = action['buy']\n",
        "        self.stock = self.stock + bought - used\n",
        "        self.stock_history.append(self.stock)\n",
        "        self.time += 1\n",
        "        price = (self.prices[self.time % len(self.prices)]  # repeating pattern\n",
        "                 + random.randrange(self.max_price_addon)  # plus randomness\n",
        "                 + self.time // 2)                          # plus inflation\n",
        "        self.price_history.append(price)\n",
        "        return {'price': price,\n",
        "                'instock': self.stock}\n",
        "\n",
        "\n",
        "def pick_from_dist(item_prob_dist):\n",
        "    \"\"\" returns a value from a distribution.\n",
        "    item_prob_dist is an item:probability dictionary, where the\n",
        "        probabilities sum to 1.\n",
        "    returns an item chosen in proportion to its probability\n",
        "    \"\"\"\n",
        "    ranreal = random.random()\n",
        "    for (it, prob) in item_prob_dist.items():\n",
        "        if ranreal < prob:\n",
        "            return it\n",
        "        else:\n",
        "            ranreal -= prob\n",
        "    raise RuntimeError(str(item_prob_dist) + \" is not a probability distribution\")\n",
        "\n",
        "\n",
        "class TP_agent(Agent):\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "        self.spent = 0\n",
        "        percepts = env.initial_percepts()\n",
        "        self.ave = self.last_price = percepts['price']\n",
        "        self.instock = percepts['instock']\n",
        "\n",
        "    def go(self, n):\n",
        "        \"\"\"go for n time steps\n",
        "        \"\"\"\n",
        "        for i in range(n):\n",
        "            if self.last_price < 0.9 * self.ave and self.instock < 60:\n",
        "                tobuy = 48\n",
        "            elif self.instock < 12:\n",
        "                tobuy = 12\n",
        "            else:\n",
        "                tobuy = 0\n",
        "            self.spent += tobuy * self.last_price\n",
        "            percepts = env.do({'buy': tobuy})\n",
        "            self.last_price = percepts['price']\n",
        "            self.ave = self.ave + (self.last_price - self.ave) * 0.05\n",
        "            self.instock = percepts['instock']\n",
        "\n",
        "\n",
        "env = TP_env()\n",
        "ag = TP_agent(env)\n",
        "# ag.go(90)\n",
        "# ag.spent/env.time   ## average spent per time period\n",
        "\n",
        "\n",
        "class Plot_prices(object):\n",
        "    \"\"\"Set up the plot for history of price and number in stock\"\"\"\n",
        "\n",
        "    def __init__(self, ag, env):\n",
        "        self.ag = ag\n",
        "        self.env = env\n",
        "        plt.ion()\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"Number in stock.                                              Price.\")\n",
        "\n",
        "    def plot_run(self):\n",
        "        \"\"\"plot history of price and instock\"\"\"\n",
        "        num = len(env.stock_history)\n",
        "        plt.plot(range(num), env.stock_history, label=\"In stock\")\n",
        "        plt.plot(range(num), env.price_history, label=\"Price\")\n",
        "        #plt.legend(loc=\"upper left\")\n",
        "        plt.draw()\n",
        "\n",
        "pl = Plot_prices(ag,env)\n",
        "ag.go(90); pl.plot_run()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}